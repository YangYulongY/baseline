{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Authentication Based on Mouse Characteristics #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# algorithms\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# optimization\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# performance\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "\n",
    "# random seed \n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/yangyulong/Documents/yzkj/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train = pd.read_pickle(data_dir + 'all_training_aggregation.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = []\n",
    "\n",
    "for root, dirs, files in os.walk(data_dir + \"training_files/\"):\n",
    "    for file in files:\n",
    "        file_paths.append(os.path.join(root, file))\n",
    "\n",
    "# randomly pick 66% of all training sessions, use these sessions to train classification models\n",
    "draw_train = np.random.randint(low=0, high=len(file_paths), size=np.floor(len(file_paths)*0.66).astype('int'))\n",
    "train_users = list(map(lambda x: x.split(os.path.sep)[-2], [file_paths[y] for y in draw_train]))\n",
    "train_sessions = list(map(lambda x: x.split(os.path.sep)[-1], [file_paths[y] for y in draw_train]))\n",
    "df_train = all_train[all_train['user'].isin(train_users) & all_train['session'].isin(train_sessions)]\n",
    "\n",
    "# the rest of the sessions are validation data\n",
    "draw_val = list(set(range(len(file_paths))) - set(draw_train))\n",
    "val_users = list(map(lambda x: x.split(os.path.sep)[-2], [file_paths[y] for y in draw_val]))\n",
    "val_sessions = list(map(lambda x: x.split(os.path.sep)[-1], [file_paths[y] for y in draw_val]))\n",
    "df_val = all_train[all_train['user'].isin(val_users) & all_train['session'].isin(val_sessions)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_user = LabelEncoder()\n",
    "le_categ = LabelEncoder()\n",
    "\n",
    "oh_user = OneHotEncoder()\n",
    "oh_categ = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le_user.fit_transform(df_train['user'])\n",
    "\n",
    "# label encode\n",
    "df_train['categ_le'] = le_categ.fit_transform(df_train['categ_agg'])\n",
    "\n",
    "# one-hot encode\n",
    "vec_size = df_train['categ_agg'].nunique()\n",
    "df_train[['oh_categ{}'.format(i) \\\n",
    "          for i in range(vec_size)]] = \\\n",
    "        pd.DataFrame(oh_categ.fit_transform(\\\n",
    "                df_train['categ_le'].values.reshape(len(df_train['categ_le']), 1)).todense(), \\\n",
    "             index=df_train.index)\n",
    "\n",
    "X_train = df_train.drop(['categ_agg', 'session', 'categ_le', 'user'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = le_user.transform(df_val['user'])\n",
    "\n",
    "# label encode\n",
    "df_val['categ_le'] = le_categ.transform(df_val['categ_agg'])\n",
    "\n",
    "# one-hot encode\n",
    "df_val[['oh_categ{}'.format(i) \\\n",
    "          for i in range(vec_size)]] = \\\n",
    "        pd.DataFrame(oh_categ.transform(\\\n",
    "                df_val['categ_le'].values.reshape(len(df_val['categ_le']), 1)).todense(), \\\n",
    "             index=df_val.index)\n",
    "\n",
    "X_val = df_val.drop(['categ_agg', 'session', 'categ_le', 'user'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Models ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a few classification models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lgb = LGBMClassifier(random_state=0)\n",
    "# clf_xgb = XGBClassifier(random_state=0)\n",
    "# clf_rf = RandomForestClassifier(random_state=0)\n",
    "# clf_lr = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given user in the training sessions, label their mouse actions as legal (`is_illegal`=0). All the other users' mouse actions are labeled illegal (`is_illegal`=1). Loop over all users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in le_user.classes_:\n",
    "    df = df_train.copy()\n",
    "    df['is_illegal'] = 0\n",
    "    # 1 = illegal session, 0 = legal session \n",
    "    df.loc[df['user'] != user, 'is_illegal'] = 1\n",
    "    X = df.drop(['categ_agg', 'session', 'categ_le', 'user', 'is_illegal'], axis=1)\n",
    "    y = df['is_illegal']\n",
    "\n",
    "    exec('clf_lgb_' + user + \" = LGBMClassifier(random_state=0)\")\n",
    "    exec('clf_lgb_' + user + \".fit(X, y)\")\n",
    "    \n",
    "    auc = eval('roc_auc_score(y, clf_lgb_' + user + \".predict_proba(X)[:, 1])\")\n",
    "    dump(eval(f'clf_lgb_{user}'), f'clf_lgb_{user}.joblib')\n",
    "\n",
    "    print(\"ROC AUC in training data for {0}: {1:0.4}\".format(user, auc))\n",
    "    \n",
    "    del df, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in le_user.classes_:\n",
    "    df = df_val.copy()\n",
    "    df['is_illegal'] = 0\n",
    "    # 1 = illegal session, 0 = legal session \n",
    "    df.loc[df['user'] != user, 'is_illegal'] = 1\n",
    "    X = df.drop(['categ_agg', 'session', 'categ_le', 'user', 'is_illegal'], axis=1)\n",
    "    y = df['is_illegal']\n",
    "\n",
    "    auc = eval('roc_auc_score(y, clf_lgb_' + user + \".predict_proba(X)[:, 1])\")\n",
    "\n",
    "    print(\"ROC AUC in validation data for {0}: {1:0.4}\".format(user, auc))\n",
    "    \n",
    "    del df, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For users other than 7 and 9 we seem to have overfit to training data. Now use cross-validation to correct overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidate hyperparameters\n",
    "gridParams = {\n",
    "    'num_leaves': [6, 8, 12, 16, 24],\n",
    "    'min_data_in_leaf': [24, 32, 40], \n",
    "    'max_bin': [32, 64, 128],\n",
    "    'max_depth': [8, 16, 32]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in le_user.classes_:\n",
    "    df = all_train.copy()\n",
    "\n",
    "    # encode\n",
    "    df['categ_le'] = le_categ.transform(df['categ_agg'])\n",
    "\n",
    "    df[['oh_categ{}'.format(i) \\\n",
    "              for i in range(vec_size)]] = \\\n",
    "            pd.DataFrame(oh_categ.transform(\\\n",
    "                    df['categ_le'].values.reshape(len(df['categ_le']), 1)).todense(), \\\n",
    "                 index=df.index)\n",
    "    \n",
    "    # define target label\n",
    "    df['is_illegal'] = 0\n",
    "\n",
    "    df.loc[df['user'] != user, 'is_illegal'] = 1\n",
    "    X = df.drop(['categ_agg', 'session', 'categ_le', 'user', 'is_illegal'], axis=1)\n",
    "    y = df['is_illegal']\n",
    "    \n",
    "    # randomized grid search\n",
    "    clf_lgb = LGBMClassifier(random_state=0)\n",
    "\n",
    "    random_search = RandomizedSearchCV(clf_lgb, scoring='roc_auc', param_distributions=gridParams)\n",
    "    random_search.fit(X, y)\n",
    "\n",
    "    # best hyperparameters\n",
    "    params = dict()    \n",
    "    params['num_leaves'] = random_search.best_params_['num_leaves']\n",
    "    params['min_data_in_leaf'] = random_search.best_params_['min_data_in_leaf']\n",
    "    params['max_bin'] = random_search.best_params_['max_bin']\n",
    "    params['max_depth'] = random_search.best_params_['max_depth']\n",
    "\n",
    "    # re-fit models\n",
    "    clf_lgb = LGBMClassifier(random_state=0, **params)\n",
    "    clf_lgb.fit(X, y)\n",
    "    \n",
    "    # AUC score\n",
    "    auc = roc_auc_score(y, clf_lgb.predict_proba(X)[:, 1])\n",
    "    print(\"ROC AUC for {0}: {1:0.4}\".format(user, auc))\n",
    "\n",
    "    # save models for each user\n",
    "    exec('clf_lgb_' + user + \" = copy.deepcopy(clf_lgb)\")\n",
    "    \n",
    "    del df, X, y, random_search, clf_lgb, auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
